{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook walks you through some helpful tools for the final project.\n",
    "## 1 Installation\n",
    "This time there is no more Vocareum! Because the project is very open-ended, your own machines will allow more creativity. So you need to install Jupyter Notebook and other packages locally. We recommend first install Anaconda, which is a Python platform that helps you to manage packages and create virtual environments. A virtual environment is a Python environment such that the Python interpreter, libraries and scripts installed into it are isolated from those installed in other virtual environments, and (by default) any libraries installed in a “system” Python, i.e., one which is installed as part of your operating system [1].\n",
    "### Recommended packages\n",
    "There are many resources out there about installing the packages we will talk about below, and we recommend you follow this order:  \n",
    "* Install Anaconda, and create a virtual environment. Then within the environment:  \n",
    "* Install Python 3.5+\n",
    "* Install Jupyter Notebook. Make sure it has \"Python 3\" listed in kernel. \n",
    "* Install the whatever packages you like, for example:  \n",
    "    * \"conda install scikit-learn\"   \n",
    "    * https://pytorch.org/get-started/locally/   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Pandas\n",
    "Pandas is a good tool to process CSV files in Python.\n",
    "\n",
    "### Basic usage\n",
    "Assume we have a file called thanksgiving.xls: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Food</th>\n",
       "      <th>Studied?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anna</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Peter</td>\n",
       "      <td>Seafood</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brian</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name     Food Studied?\n",
       "0   Anna   Turkey       No\n",
       "1  Peter  Seafood       No\n",
       "2  Brian   Turkey      Yes"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# You always need to use this as a start: read the csv file into the memory. \n",
    "# The return will be a pandas.DataFrame object.\n",
    "df = pd.read_excel('./thanksgiving.xls')\n",
    "# Gives you first few rows.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Turkey\n",
       "1    Seafood\n",
       "2     Turkey\n",
       "Name: Food, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select single column\n",
    "df['Food']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Anna', 'No'],\n",
       "       ['Peter', 'No'],\n",
       "       ['Brian', 'Yes']], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you select multiple colomns, use a list for indices\n",
    "df[['Name', 'Studied?']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Food</th>\n",
       "      <th>Studied?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anna</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brian</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name    Food Studied?\n",
       "0   Anna  Turkey       No\n",
       "2  Brian  Turkey      Yes"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Row selection\n",
    "df[df[\"Food\"] =='Turkey']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may also look into how to find NANs in the csv, how to convert a DataFrame into a numpy array, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Sklearn\n",
    "Scikit-learn is a free machine learning library for Python. It features various algorithms like support vector machine, random forests, and k-neighbours, and it also supports Python numerical and scientific libraries like NumPy and SciPy [2]. So this is a great tool to help you complete the baseline part of this project.\n",
    "\n",
    "### Basic Usage [3]\n",
    "Although the mechanisms of different ML algorithms varies a lot, Sklearn provide some neat functions which almost all of them share, so you don't need much code to try many algorithms.\n",
    " \n",
    "__fit(X, y)__  \n",
    "Fit the model using X as training data and y as target values\n",
    "\n",
    "__get_params([deep])__  \n",
    "Get parameters for this estimator.\n",
    "\n",
    "__predict(X)__  \n",
    "Predict the class labels for the provided data.\n",
    "\n",
    "__predict_proba(X)__  \n",
    "Return probability estimates for the test data X.\n",
    "\n",
    "__score(X, y[, sample_weight])__  \n",
    "Return the mean accuracy on the given test data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[[0.66666667 0.33333333]]\n"
     ]
    }
   ],
   "source": [
    "# example \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "X = [[0], [1], [2], [3]]\n",
    "y = [0, 0, 1, 1]\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X, y)\n",
    "print(neigh.predict([[1.1],[3.5]]))\n",
    "print(neigh.predict_proba([[0.9]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Pytorch\n",
    "If you are not satisfied with the baseline methods, here is the more advanced part: neural networks (NN)! Considering most students won't have access to GPUs, we keep the data size for this project very small, so you may start with trying Pytorch with the CPU version. However, please remember once the data or the model gets larger, as they always do in real research, using CPUs alone would be too slow.\n",
    "\n",
    "We recommend Pytorch as the deep learning framework due to its popularity and similarity with numpy. If you want to know more about the comparison between Pytorch and Tensorflow, here’s some good articles: https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/, https://towardsdatascience.com/pytorch-vs-tensorflow-in-2020-fe237862fae1.\n",
    "\n",
    "The basic pipeline contains 5 steps: prepare the data, build the model, training, validating, and testing. We will give a short introduction for the first three, since the code for validating and testing are kind of similar with training.\n",
    "\n",
    "### Data preparation\n",
    "To create your own dataset, you always need to inherit the torch.utils.data.Dataset class by implement the following methods yourself, because it is the interface between a customized dataset and the general torch.utils.data.Dataloader that can process any dataset with those methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        # Where the initial logic happens like reading a csv, doing data augmentation, etc.\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self):\n",
    "        # Returns count of samples (an integer) you have. \n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Given an index, returns the correponding datapoint. \n",
    "        # This function is called from dataloader like this:\n",
    "        # img, label = CSVDataset.__getitem__(99)  # For 99th item\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "Similarly, to build your own model, you always need to inherit the torch.nn.Module class and implement the following 2 methods, so that your model can be called as __prediction=model(data)__. Below is an example of CNN, but for this project maybe a MLP is enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        You need to initialize most NN layers here.\n",
    "        \"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Define in what order the input x is forwarded through all the NN layers to become a final output. \n",
    "        \"\"\"\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training \n",
    "The example below provides the most fundamental steps that training a NN would take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train(csv_file):\n",
    "    # Initialize an object of the model class\n",
    "    net = Net()\n",
    "    # Define your loss function\n",
    "    criterion = nn.MSELoss()\n",
    "    # Create your optimizer\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "    # Initialize an object of the dataset class\n",
    "    dataset = CSVDataset(csv_file)\n",
    "    # Wrap a dataloader around the dataset object.\n",
    "    dataloader = Dataloader(dataset)\n",
    "    # Beging training!\n",
    "    for batch_idx, (input, target) in enumerate(dataloader):\n",
    "        # You always want to use zero_grad(), backward(), and step() in the following order.\n",
    "        # zero_grad clears old gradients from the last step (otherwise you’d just accumulate the gradients from all loss.backward() calls).\n",
    "        optimizer.zero_grad()\n",
    "        # As said before, you can only code as below if your network belongs to the nn.Module class.\n",
    "        output = net(input)\n",
    "        loss = criterion(output, target)\n",
    "        # loss.backward() computes the derivative of the loss w.r.t. the parameters (or anything requiring gradients) using backpropagation.\n",
    "        loss.backward()\n",
    "        # optimizer.step() causes the optimizer to take a step based on the gradients of the parameters.\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Reference\n",
    "[1] https://docs.python.org/3/library/venv.html#:~:text=A%20virtual%20environment%20is%20a,part%20of%20your%20operating%20system.  \n",
    "[2] https://www.dataquest.io/blog/sci-kit-learn-tutorial.  \n",
    "[3] http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
